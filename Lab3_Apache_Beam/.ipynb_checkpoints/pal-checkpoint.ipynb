{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens Data Pipeline with Apache Beam\n",
    "\n",
    "This notebook demonstrates a complete ETL pipeline using Apache Beam to analyze movie data from the MovieLens dataset.\n",
    "\n",
    "## Pipeline Overview\n",
    "- **Input**: MovieLens CSV files (movies.csv, ratings.csv)\n",
    "- **Processing**: Data cleaning, joining, aggregations\n",
    "- **Output**: 5 analytical CSV reports\n",
    "\n",
    "## Outputs Generated\n",
    "1. Average rating by genre\n",
    "2. Top-N highest rated movies per genre\n",
    "3. Movie statistics by decade\n",
    "4. Rating distribution analysis\n",
    "5. Popularity analysis (Popular/Moderate/Niche)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Apache Beam (run once)\n",
    "!pip install apache-beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "from typing import Dict, Iterable, List\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "These functions handle:\n",
    "- Safe type conversions (str → float, str → int)\n",
    "- CSV formatting for output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float_safe(x: str) -> float:\n",
    "    \"\"\"Safely convert string to float, returns NaN on error\"\"\"\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "\n",
    "def to_int_safe(x: str):\n",
    "    \"\"\"Safely convert string to int, returns None on error\"\"\"\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def format_csv_line(fields: Iterable) -> str:\n",
    "    \"\"\"Format a tuple/list as a CSV line\"\"\"\n",
    "    out = io.StringIO()\n",
    "    csv.writer(out).writerow(list(fields))\n",
    "    return out.getvalue().rstrip(\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DoFn Classes\n",
    "\n",
    "Apache Beam uses DoFn (Do Function) classes to define transformations on data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ParseCSV - Converts CSV lines to dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseCSV(beam.DoFn):\n",
    "    \"\"\"\n",
    "    Parses CSV lines to dicts using a known header.\n",
    "    Skips the header line and blank lines.\n",
    "    \"\"\"\n",
    "    def __init__(self, header_line: str):\n",
    "        self.header_line = header_line\n",
    "        self._fieldnames: List[str] = []\n",
    "\n",
    "    def setup(self):\n",
    "        # Parse header to get column names\n",
    "        self._fieldnames = next(csv.reader([self.header_line]))\n",
    "\n",
    "    def process(self, line: str) -> Iterable[Dict]:\n",
    "        line = line.strip()\n",
    "        if not line or line == self.header_line:\n",
    "            return\n",
    "        \n",
    "        # Parse CSV row and create dictionary\n",
    "        values = next(csv.reader([line]))\n",
    "        if len(values) < len(self._fieldnames):\n",
    "            values = values + [\"\"] * (len(self._fieldnames) - len(values))\n",
    "        row = dict(zip(self._fieldnames, values))\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PreprocessMovies - Cleans and enriches movie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessMovies(beam.DoFn):\n",
    "    \"\"\"\n",
    "    Preprocesses movie data:\n",
    "    - Extracts year from title (e.g., \"Toy Story (1995)\" → 1995)\n",
    "    - Parses genres (e.g., \"Action|Adventure|Sci-Fi\" → [\"Action\", \"Adventure\", \"Sci-Fi\"])\n",
    "    - Creates decade field (e.g., 1995 → 1990)\n",
    "    - Filters out invalid entries\n",
    "    \"\"\"\n",
    "    def process(self, row: Dict) -> Iterable[Dict]:\n",
    "        title = row.get(\"title\", \"\")\n",
    "        \n",
    "        # Extract year from title (format: \"Movie Title (1999)\")\n",
    "        year = None\n",
    "        if \"(\" in title and \")\" in title:\n",
    "            try:\n",
    "                year_str = title.split(\"(\")[-1].split(\")\")[0]\n",
    "                year = int(year_str)\n",
    "                if year < 1900 or year > 2025:\n",
    "                    year = None\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if year is None:\n",
    "            return  # Skip movies without valid year\n",
    "        \n",
    "        row[\"year\"] = year\n",
    "        row[\"decade\"] = (year // 10) * 10\n",
    "        \n",
    "        # Parse genres (format: \"Action|Adventure|Sci-Fi\")\n",
    "        genres = row.get(\"genres\", \"\")\n",
    "        if not genres or genres == \"(no genres listed)\":\n",
    "            return  # Skip movies without genres\n",
    "        \n",
    "        genre_list = genres.split(\"|\")\n",
    "        row[\"primaryGenre\"] = genre_list[0]\n",
    "        row[\"allGenres\"] = genre_list\n",
    "        \n",
    "        yield row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. JoinWithRatings - Joins movies with their ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoinWithRatings(beam.DoFn):\n",
    "    \"\"\"\n",
    "    Enriches movie data with rating information:\n",
    "    - Joins movies with their ratings using CoGroupByKey results\n",
    "    - Calculates average rating from all user ratings\n",
    "    - Counts number of ratings per movie\n",
    "    - Filters movies with < 10 ratings (quality threshold)\n",
    "    \"\"\"\n",
    "    def process(self, element) -> Iterable[Dict]:\n",
    "        movie_id, data = element\n",
    "        movies_list = data.get(\"movies\", [])\n",
    "        ratings_list = data.get(\"ratings\", [])\n",
    "        \n",
    "        # Skip if no movie or ratings found\n",
    "        if not movies_list or not ratings_list:\n",
    "            return\n",
    "        \n",
    "        movie = movies_list[0]\n",
    "        \n",
    "        # Calculate average rating from all user ratings\n",
    "        total_rating = 0\n",
    "        count = 0\n",
    "        for rating_row in ratings_list:\n",
    "            rating = to_float_safe(rating_row.get(\"rating\", \"\"))\n",
    "            if rating == rating:  # Check if not NaN\n",
    "                total_rating += rating\n",
    "                count += 1\n",
    "        \n",
    "        if count == 0:\n",
    "            return\n",
    "        \n",
    "        movie[\"averageRating\"] = round(total_rating / count, 2)\n",
    "        movie[\"numRatings\"] = count\n",
    "        \n",
    "        # Only keep movies with at least 10 ratings\n",
    "        if count >= 10:\n",
    "            yield movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "MOVIES_FILE = \"data/movies.csv\"\n",
    "RATINGS_FILE = \"data/ratings.csv\"\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "TOP_N = 10  # Top N movies per genre\n",
    "\n",
    "# Read headers from files\n",
    "with open(MOVIES_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    movies_header = f.readline().strip()\n",
    "\n",
    "with open(RATINGS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    ratings_header = f.readline().strip()\n",
    "\n",
    "print(f\"Movies header: {movies_header}\")\n",
    "print(f\"Ratings header: {ratings_header}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Pipeline\n",
    "\n",
    "The pipeline consists of:\n",
    "1. **Data Ingestion**: Read CSV files\n",
    "2. **Data Preprocessing**: Clean and enrich data\n",
    "3. **Data Join**: Combine movies with ratings\n",
    "4. **Analysis**: Generate 5 different analytical outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline options\n",
    "opts = PipelineOptions()\n",
    "\n",
    "# Run the pipeline\n",
    "with beam.Pipeline(options=opts) as p:\n",
    "    \n",
    "    # ========================================\n",
    "    # STEP 1: Read and preprocess movies\n",
    "    # ========================================\n",
    "    movies_raw = (\n",
    "        p \n",
    "        | \"ReadMovies\" >> beam.io.ReadFromText(MOVIES_FILE)\n",
    "        | \"ParseMovies\" >> beam.ParDo(ParseCSV(movies_header))\n",
    "        | \"PreprocessMovies\" >> beam.ParDo(PreprocessMovies())\n",
    "        | \"KeyMoviesByID\" >> beam.Map(lambda r: (r[\"movieId\"], r))\n",
    "    )\n",
    "    \n",
    "    # ========================================\n",
    "    # STEP 2: Read ratings\n",
    "    # ========================================\n",
    "    ratings_raw = (\n",
    "        p\n",
    "        | \"ReadRatings\" >> beam.io.ReadFromText(RATINGS_FILE)\n",
    "        | \"ParseRatings\" >> beam.ParDo(ParseCSV(ratings_header))\n",
    "        | \"KeyRatingsByID\" >> beam.Map(lambda r: (r[\"movieId\"], r))\n",
    "    )\n",
    "    \n",
    "    # ========================================\n",
    "    # STEP 3: Join movies with ratings\n",
    "    # ========================================\n",
    "    movies = (\n",
    "        {\"movies\": movies_raw, \"ratings\": ratings_raw}\n",
    "        | \"CoGroupByKey\" >> beam.CoGroupByKey()\n",
    "        | \"JoinWithRatings\" >> beam.ParDo(JoinWithRatings())\n",
    "    )\n",
    "\n",
    "    # ========================================\n",
    "    # OUTPUT 1: Average rating by genre\n",
    "    # ========================================\n",
    "    genre_rating = (\n",
    "        movies\n",
    "        | \"KeyByGenre\" >> beam.Map(lambda r: (r[\"primaryGenre\"], r[\"averageRating\"]))\n",
    "        | \"GroupRatingByGenre\" >> beam.GroupByKey()\n",
    "        | \"AvgRating\" >> beam.Map(\n",
    "            lambda kv: (kv[0], sum(kv[1]) / len(list(kv[1])))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    rating_header = p | \"RatingHeader\" >> beam.Create(\n",
    "        [format_csv_line((\"genre\", \"avg_rating\"))]\n",
    "    )\n",
    "\n",
    "    rating_rows = (\n",
    "        genre_rating\n",
    "        | \"FormatRatingRows\" >> beam.Map(\n",
    "            lambda kv: format_csv_line((kv[0], f\"{kv[1]:.2f}\"))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    _ = ((rating_header, rating_rows)\n",
    "         | \"RatingFlatten\" >> beam.Flatten()\n",
    "         | \"WriteRatingCSV\" >> beam.io.WriteToText(\n",
    "                file_path_prefix=f\"{OUTPUT_DIR}/genre_avg_rating\",\n",
    "                file_name_suffix=\".csv\",\n",
    "                num_shards=1\n",
    "            )\n",
    "    )\n",
    "\n",
    "    # ========================================\n",
    "    # OUTPUT 2: Top-N highest rated movies per genre\n",
    "    # ========================================\n",
    "    genre_movie_ratings = (\n",
    "        movies\n",
    "        | \"KeyByGenreMovie\" >>\n",
    "            beam.Map(lambda r: (r[\"primaryGenre\"], \n",
    "                               (r[\"title\"], r[\"averageRating\"], r[\"numRatings\"])))\n",
    "        | \"GroupByGenre\" >> beam.GroupByKey()\n",
    "        | \"SortByRating\" >> beam.Map(\n",
    "            lambda kv: (kv[0], sorted(kv[1], key=lambda x: x[1], reverse=True))\n",
    "        )\n",
    "        | \"TakeTopN\" >> beam.Map(lambda kv: (kv[0], kv[1][:TOP_N]))\n",
    "        | \"ExplodeTopN\" >> beam.FlatMap(\n",
    "            lambda kv: [(kv[0], title, rating, votes) for (title, rating, votes) in kv[1]]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    topn_header = p | \"TopNHeader\" >> beam.Create(\n",
    "        [format_csv_line((\"genre\", \"title\", \"rating\", \"num_ratings\"))]\n",
    "    )\n",
    "    \n",
    "    topn_rows = (\n",
    "        genre_movie_ratings\n",
    "        | \"FormatTopNRows\" >> beam.Map(\n",
    "            lambda t: format_csv_line((t[0], t[1], f\"{t[2]:.2f}\", t[3]))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    _ = ((topn_header, topn_rows)\n",
    "         | \"TopNFlatten\" >> beam.Flatten()\n",
    "         | \"WriteTopNCSV\" >> beam.io.WriteToText(\n",
    "                file_path_prefix=f\"{OUTPUT_DIR}/top{TOP_N}_movies_by_genre\",\n",
    "                file_name_suffix=\".csv\",\n",
    "                num_shards=1\n",
    "            )\n",
    "    )\n",
    "\n",
    "    # ========================================\n",
    "    # OUTPUT 3: Movie count and average rating by decade\n",
    "    # ========================================\n",
    "    decade_stats = (\n",
    "        movies\n",
    "        | \"KeyByDecade\" >> beam.Map(lambda r: (r[\"decade\"], \n",
    "                                               (r[\"averageRating\"], 1)))\n",
    "        | \"GroupByDecade\" >> beam.GroupByKey()\n",
    "        | \"ComputeDecadeStats\" >> beam.Map(\n",
    "            lambda kv: (\n",
    "                kv[0], \n",
    "                len(list(kv[1])),\n",
    "                sum(x[0] for x in kv[1]) / len(list(kv[1]))\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    decade_header = p | \"DecadeHeader\" >> beam.Create(\n",
    "        [format_csv_line((\"decade\", \"movie_count\", \"avg_rating\"))]\n",
    "    )\n",
    "\n",
    "    decade_rows = (\n",
    "        decade_stats\n",
    "        | \"FormatDecadeRows\" >> beam.Map(\n",
    "            lambda t: format_csv_line((f\"{t[0]}s\", t[1], f\"{t[2]:.2f}\"))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    _ = ((decade_header, decade_rows)\n",
    "         | \"DecadeFlatten\" >> beam.Flatten()\n",
    "         | \"WriteDecadeCSV\" >> beam.io.WriteToText(\n",
    "                file_path_prefix=f\"{OUTPUT_DIR}/decade_statistics\",\n",
    "                file_name_suffix=\".csv\",\n",
    "                num_shards=1\n",
    "            )\n",
    "    )\n",
    "\n",
    "    # ========================================\n",
    "    # OUTPUT 4: Rating distribution buckets\n",
    "    # ========================================\n",
    "    rating_buckets = (\n",
    "        movies\n",
    "        | \"CreateRatingBuckets\" >> beam.Map(\n",
    "            lambda r: (int(r[\"averageRating\"]), 1)\n",
    "        )\n",
    "        | \"SumRatingBuckets\" >> beam.CombinePerKey(sum)\n",
    "    )\n",
    "\n",
    "    rating_bucket_header = p | \"RatingBucketHeader\" >> beam.Create(\n",
    "        [format_csv_line((\"rating_bucket\", \"movie_count\"))]\n",
    "    )\n",
    "\n",
    "    rating_bucket_rows = (\n",
    "        rating_buckets\n",
    "        | \"FormatRatingBuckets\" >> beam.Map(\n",
    "            lambda kv: format_csv_line((f\"{kv[0]}-{kv[0]+1}\", kv[1]))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    _ = ((rating_bucket_header, rating_bucket_rows)\n",
    "         | \"RatingBucketFlatten\" >> beam.Flatten()\n",
    "         | \"WriteRatingBucketCSV\" >> beam.io.WriteToText(\n",
    "                file_path_prefix=f\"{OUTPUT_DIR}/rating_distribution\",\n",
    "                file_name_suffix=\".csv\",\n",
    "                num_shards=1\n",
    "            )\n",
    "    )\n",
    "\n",
    "    # ========================================\n",
    "    # OUTPUT 5: Popular vs Niche movies analysis\n",
    "    # ========================================\n",
    "    popularity_category = (\n",
    "        movies\n",
    "        | \"CategorizePopularity\" >> beam.Map(\n",
    "            lambda r: (\n",
    "                \"Popular\" if r[\"numRatings\"] >= 100 \n",
    "                else \"Moderate\" if r[\"numRatings\"] >= 50 \n",
    "                else \"Niche\",\n",
    "                (r[\"averageRating\"], 1)\n",
    "            )\n",
    "        )\n",
    "        | \"GroupByPopularity\" >> beam.GroupByKey()\n",
    "        | \"ComputePopularityStats\" >> beam.Map(\n",
    "            lambda kv: (\n",
    "                kv[0],\n",
    "                len(list(kv[1])),\n",
    "                sum(x[0] for x in kv[1]) / len(list(kv[1]))\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    popularity_header = p | \"PopularityHeader\" >> beam.Create(\n",
    "        [format_csv_line((\"popularity_category\", \"movie_count\", \"avg_rating\"))]\n",
    "    )\n",
    "\n",
    "    popularity_rows = (\n",
    "        popularity_category\n",
    "        | \"FormatPopularityRows\" >> beam.Map(\n",
    "            lambda t: format_csv_line((t[0], t[1], f\"{t[2]:.2f}\"))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    _ = ((popularity_header, popularity_rows)\n",
    "         | \"PopularityFlatten\" >> beam.Flatten()\n",
    "         | \"WritePopularityCSV\" >> beam.io.WriteToText(\n",
    "                file_path_prefix=f\"{OUTPUT_DIR}/popularity_analysis\",\n",
    "                file_name_suffix=\".csv\",\n",
    "                num_shards=1\n",
    "            )\n",
    "    )\n",
    "\n",
    "print(\"\\n✅ Pipeline completed successfully!\")\n",
    "print(f\"\\nOutput files created in '{OUTPUT_DIR}/' directory:\")\n",
    "print(\"  1. genre_avg_rating-00000-of-00001.csv\")\n",
    "print(f\"  2. top{TOP_N}_movies_by_genre-00000-of-00001.csv\")\n",
    "print(\"  3. decade_statistics-00000-of-00001.csv\")\n",
    "print(\"  4. rating_distribution-00000-of-00001.csv\")\n",
    "print(\"  5. popularity_analysis-00000-of-00001.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results\n",
    "\n",
    "Let's preview the generated output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read and display output files\n",
    "output_files = [\n",
    "    \"genre_avg_rating-00000-of-00001.csv\",\n",
    "    f\"top{TOP_N}_movies_by_genre-00000-of-00001.csv\",\n",
    "    \"decade_statistics-00000-of-00001.csv\",\n",
    "    \"rating_distribution-00000-of-00001.csv\",\n",
    "    \"popularity_analysis-00000-of-00001.csv\"\n",
    "]\n",
    "\n",
    "for file in output_files:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"📊 {file}\")\n",
    "    print('='*60)\n",
    "    df = pd.read_csv(f\"{OUTPUT_DIR}/{file}\")\n",
    "    print(df.head(10))\n",
    "    print(f\"\\nTotal rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all outputs for summary\n",
    "genre_ratings = pd.read_csv(f\"{OUTPUT_DIR}/genre_avg_rating-00000-of-00001.csv\")\n",
    "decade_stats = pd.read_csv(f\"{OUTPUT_DIR}/decade_statistics-00000-of-00001.csv\")\n",
    "rating_dist = pd.read_csv(f\"{OUTPUT_DIR}/rating_distribution-00000-of-00001.csv\")\n",
    "popularity = pd.read_csv(f\"{OUTPUT_DIR}/popularity_analysis-00000-of-00001.csv\")\n",
    "\n",
    "print(\"📈 PIPELINE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total genres analyzed: {len(genre_ratings)}\")\n",
    "print(f\"Decades covered: {len(decade_stats)}\")\n",
    "print(f\"Rating buckets: {len(rating_dist)}\")\n",
    "print(f\"\\nTop rated genre: {genre_ratings.loc[genre_ratings['avg_rating'].idxmax(), 'genre']}\")\n",
    "print(f\"Most productive decade: {decade_stats.loc[decade_stats['movie_count'].idxmax(), 'decade']}\")\n",
    "print(f\"\\nPopularity breakdown:\")\n",
    "print(popularity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}