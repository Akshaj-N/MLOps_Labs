{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens Data Pipeline with Apache Beam\n",
    "\n",
    "This notebook demonstrates a complete ETL pipeline using Apache Beam to analyze movie data from the MovieLens dataset. The pipeline reads movie and rating data, performs data cleaning and enrichment, joins datasets and generates five analytical reports providing insights into movie ratings, genres and popularity trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Overview\n",
    "- **Input**: MovieLens CSV files (movies.csv, ratings.csv)\n",
    "- **Processing**: Data cleaning, joining, aggregations\n",
    "- **Output**:\n",
    "  - Average rating by genre  \n",
    "  - Top-N highest rated movies per genre  \n",
    "  - Movie statistics by decade  \n",
    "  - Rating distribution analysis  \n",
    "  - Popularity analysis (Popular / Moderate / Niche)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install Apache Beam (i have run once)\n",
    "!pip install apache-beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import csv\n",
    "from typing import Dict, Iterable, List\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "These utility functions help with:\n",
    "- **Safe type conversions:** Convert strings to float/int\n",
    "- **CSV formatting:** Properly format data for CSV output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float_safe(x: str) -> float:\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "\n",
    "def to_int_safe(x: str):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def format_csv_line(fields: Iterable) -> str:\n",
    "    out = io.StringIO()\n",
    "    csv.writer(out).writerow(list(fields))\n",
    "    return out.getvalue().rstrip(\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Beam Transformations (DoFn Classes)\n",
    "\n",
    "Apache Beam uses DoFn (Do Function) classes to define data transformations. Each DoFn processes elements in a PCollection (Parallel Collection) and can:\n",
    "- Filter elements\n",
    "- Modify data\n",
    "- Add new fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ParseCSV - Converts CSV lines to dictionaries\n",
    "\n",
    "This DoFn reads CSV text lines and converts them into Python dictionaries with column names as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseCSV(beam.DoFn):\n",
    "    def __init__(self, header_line: str):\n",
    "        self.header_line = header_line\n",
    "        self._fieldnames: List[str] = []\n",
    "\n",
    "    def setup(self):\n",
    "        self._fieldnames = next(csv.reader([self.header_line]))\n",
    "\n",
    "    def process(self, line: str) -> Iterable[Dict]:\n",
    "        line = line.strip()\n",
    "        if not line or line == self.header_line:\n",
    "            return\n",
    "        \n",
    "        # parse CSV row and create dictionary\n",
    "        values = next(csv.reader([line]))\n",
    "        if len(values) < len(self._fieldnames):\n",
    "            values = values + [\"\"] * (len(self._fieldnames) - len(values))\n",
    "        row = dict(zip(self._fieldnames, values))\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PreprocessMovies - Cleans and enriches movie data\n",
    "\n",
    "This DoFn:\n",
    "- Extracts year from title: \"Toy Story (1995)\" → year = 1995\n",
    "- Calculates decade: 1995 → 1990\n",
    "- Parses genres: \"Action|Adventure\" → [\"Action\", \"Adventure\"]\n",
    "- Filters invalid entries (missing year or genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessMovies(beam.DoFn):\n",
    "    def process(self, row: Dict) -> Iterable[Dict]:\n",
    "        title = row.get(\"title\", \"\")\n",
    "        year = None\n",
    "        if \"(\" in title and \")\" in title:\n",
    "            try:\n",
    "                year_str = title.split(\"(\")[-1].split(\")\")[0]\n",
    "                year = int(year_str)\n",
    "                if year < 1900 or year > 2025:\n",
    "                    year = None\n",
    "            except:\n",
    "                pass   \n",
    "        if year is None:\n",
    "            return  # skip movies without valid year\n",
    "        row[\"year\"] = year\n",
    "        row[\"decade\"] = (year // 10) * 10\n",
    "        \n",
    "        # parse genres \n",
    "        genres = row.get(\"genres\", \"\")\n",
    "        if not genres or genres == \"(no genres listed)\":\n",
    "            return  # skip movies without genres\n",
    "        genre_list = genres.split(\"|\")\n",
    "        row[\"primaryGenre\"] = genre_list[0]\n",
    "        row[\"allGenres\"] = genre_list\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. JoinWithRatings - Joins movies with their ratings\n",
    "\n",
    "This DoFn:\n",
    "- Receives results from CoGroupByKey (grouped by movie ID)\n",
    "- Calculates average rating from all user ratings\n",
    "- Counts number of ratings per movie\n",
    "- Filters movies with less than 10 ratings (quality threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoinWithRatings(beam.DoFn):\n",
    "    def process(self, element) -> Iterable[Dict]:\n",
    "        movie_id, data = element\n",
    "        movies_list = data.get(\"movies\", [])\n",
    "        ratings_list = data.get(\"ratings\", [])\n",
    "        \n",
    "        # skipping if no movie or ratings found\n",
    "        if not movies_list or not ratings_list:\n",
    "            return        \n",
    "        movie = movies_list[0]\n",
    "\n",
    "        # calculating average rating from all user ratings\n",
    "        total_rating = 0\n",
    "        count = 0\n",
    "        for rating_row in ratings_list:\n",
    "            rating = to_float_safe(rating_row.get(\"rating\", \"\"))\n",
    "            if rating == rating:  # Check if not NaN\n",
    "                total_rating += rating\n",
    "                count += 1\n",
    "        if count == 0:\n",
    "            return\n",
    "        movie[\"averageRating\"] = round(total_rating / count, 2)\n",
    "        movie[\"numRatings\"] = count\n",
    "        if count >= 10:\n",
    "            yield movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Configuration\n",
    "\n",
    "Set up configuration parameters for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies header: movieId,title,genres\n",
      "Ratings header: userId,movieId,rating,timestamp\n"
     ]
    }
   ],
   "source": [
    "# configuration parameters\n",
    "MOVIES_FILE = \"data/movies.csv\"\n",
    "RATINGS_FILE = \"data/ratings.csv\"\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "TOP_N = 10 \n",
    "\n",
    "# reading headers from files\n",
    "with open(MOVIES_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    movies_header = f.readline().strip()\n",
    "\n",
    "with open(RATINGS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    ratings_header = f.readline().strip()\n",
    "\n",
    "print(f\"Movies header: {movies_header}\")\n",
    "print(f\"Ratings header: {ratings_header}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Pipeline\n",
    "\n",
    "### Pipeline Structure:\n",
    "1. **Read & Parse**: Load CSV files and convert to dictionaries\n",
    "2. **Preprocess**: Clean and enrich movie data\n",
    "3. **Join**: Combine movies with ratings using movieId as key\n",
    "4. **Analyze**: Generate 5 different analytical outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/Users/akshajnevgi/Library/Jupyter/runtime/kernel-e33b1464-5bbe-4f89-9fe3-f7039978fd75.json']\n",
      "WARNING:apache_beam.transforms.core:Using yield and return in the process method of <class '__main__.PreprocessMovies'> can lead to unexpected behavior, see:https://github.com/apache/beam/issues/22969.\n",
      "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class '__main__.JoinWithRatings'>)\n",
      "WARNING:apache_beam.transforms.core:Using yield and return in the process method of <class '__main__.JoinWithRatings'> can lead to unexpected behavior, see:https://github.com/apache/beam/issues/22969.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/Users/akshajnevgi/Library/Jupyter/runtime/kernel-e33b1464-5bbe-4f89-9fe3-f7039978fd75.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/Users/akshajnevgi/Library/Jupyter/runtime/kernel-e33b1464-5bbe-4f89-9fe3-f7039978fd75.json']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Pipeline completed successfully !\n"
     ]
    }
   ],
   "source": [
    "# creating pipeline options\n",
    "opts = PipelineOptions()\n",
    "with beam.Pipeline(options=opts) as p:\n",
    "    \n",
    "    # Read and preprocess movies\n",
    "    movies_raw = (\n",
    "        p \n",
    "        | \"ReadMovies\" >> beam.io.ReadFromText(MOVIES_FILE)\n",
    "        | \"ParseMovies\" >> beam.ParDo(ParseCSV(movies_header))\n",
    "        | \"PreprocessMovies\" >> beam.ParDo(PreprocessMovies())\n",
    "        | \"KeyMoviesByID\" >> beam.Map(lambda r: (r[\"movieId\"], r))\n",
    "    )\n",
    "    \n",
    "    # Read ratings\n",
    "    ratings_raw = (\n",
    "        p\n",
    "        | \"ReadRatings\" >> beam.io.ReadFromText(RATINGS_FILE)\n",
    "        | \"ParseRatings\" >> beam.ParDo(ParseCSV(ratings_header))\n",
    "        | \"KeyRatingsByID\" >> beam.Map(lambda r: (r[\"movieId\"], r))\n",
    "    )\n",
    "    \n",
    "    # Join movies with ratings\n",
    "    movies = (\n",
    "        {\"movies\": movies_raw, \"ratings\": ratings_raw}\n",
    "        | \"CoGroupByKey\" >> beam.CoGroupByKey()\n",
    "        | \"JoinWithRatings\" >> beam.ParDo(JoinWithRatings())\n",
    "    )\n",
    "\n",
    "    # Output 1 - Average rating by genre\n",
    "    genre_rating = (\n",
    "        movies\n",
    "        | \"KeyByGenre\" >> beam.Map(lambda r: (r[\"primaryGenre\"], r[\"averageRating\"]))\n",
    "        | \"GroupRatingByGenre\" >> beam.GroupByKey()\n",
    "        | \"AvgRating\" >> beam.Map(\n",
    "            lambda kv: (kv[0], sum(kv[1]) / len(list(kv[1])))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    rating_header = p | \"RatingHeader\" >> beam.Create(\n",
    "        [format_csv_line((\"genre\", \"avg_rating\"))]\n",
    "    )\n",
    "\n",
    "    rating_rows = (\n",
    "        genre_rating\n",
    "        | \"FormatRatingRows\" >> beam.Map(\n",
    "            lambda kv: format_csv_line((kv[0], f\"{kv[1]:.2f}\"))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    _ = ((rating_header, rating_rows)\n",
    "         | \"RatingFlatten\" >> beam.Flatten()\n",
    "         | \"WriteRatingCSV\" >> beam.io.WriteToText(\n",
    "                file_path_prefix=f\"{OUTPUT_DIR}/genre_avg_rating\",\n",
    "                file_name_suffix=\".csv\",\n",
    "                num_shards=1\n",
    "            )\n",
    "    )\n",
    "\n",
    "    # Output 2 - Top-N highest rated movies per genre\n",
    "    genre_movie_ratings = (\n",
    "        movies\n",
    "        | \"KeyByGenreMovie\" >>\n",
    "            beam.Map(lambda r: (r[\"primaryGenre\"], \n",
    "                               (r[\"title\"], r[\"averageRating\"], r[\"numRatings\"])))\n",
    "        | \"GroupByGenre\" >> beam.GroupByKey()\n",
    "        | \"SortByRating\" >> beam.Map(\n",
    "            lambda kv: (kv[0], sorted(kv[1], key=lambda x: x[1], reverse=True))\n",
    "        )\n",
    "        | \"TakeTopN\" >> beam.Map(lambda kv: (kv[0], kv[1][:TOP_N]))\n",
    "        | \"ExplodeTopN\" >> beam.FlatMap(\n",
    "            lambda kv: [(kv[0], title, rating, votes) for (title, rating, votes) in kv[1]]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    topn_header = p | \"TopNHeader\" >> beam.Create(\n",
    "        [format_csv_line((\"genre\", \"title\", \"rating\", \"num_ratings\"))]\n",
    "    )\n",
    "    \n",
    "    topn_rows = (\n",
    "        genre_movie_ratings\n",
    "        | \"FormatTopNRows\" >> beam.Map(\n",
    "            lambda t: format_csv_line((t[0], t[1], f\"{t[2]:.2f}\", t[3]))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    _ = ((topn_header, topn_rows)\n",
    "         | \"TopNFlatten\" >> beam.Flatten()\n",
    "         | \"WriteTopNCSV\" >> beam.io.WriteToText(\n",
    "                file_path_prefix=f\"{OUTPUT_DIR}/top{TOP_N}_movies_by_genre\",\n",
    "                file_name_suffix=\".csv\",\n",
    "                num_shards=1\n",
    "            )\n",
    "    )\n",
    "\n",
    "    # Output 3: Movie count and average rating by decade\n",
    "    decade_stats = (\n",
    "        movies\n",
    "        | \"KeyByDecade\" >> beam.Map(lambda r: (r[\"decade\"], \n",
    "                                               (r[\"averageRating\"], 1)))\n",
    "        | \"GroupByDecade\" >> beam.GroupByKey()\n",
    "        | \"ComputeDecadeStats\" >> beam.Map(\n",
    "            lambda kv: (\n",
    "                kv[0], \n",
    "                len(list(kv[1])),\n",
    "                sum(x[0] for x in kv[1]) / len(list(kv[1]))\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    decade_header = p | \"DecadeHeader\" >> beam.Create(\n",
    "        [format_csv_line((\"decade\", \"movie_count\", \"avg_rating\"))]\n",
    "    )\n",
    "\n",
    "    decade_rows = (\n",
    "        decade_stats\n",
    "        | \"FormatDecadeRows\" >> beam.Map(\n",
    "            lambda t: format_csv_line((f\"{t[0]}s\", t[1], f\"{t[2]:.2f}\"))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    _ = ((decade_header, decade_rows)\n",
    "         | \"DecadeFlatten\" >> beam.Flatten()\n",
    "         | \"WriteDecadeCSV\" >> beam.io.WriteToText(\n",
    "                file_path_prefix=f\"{OUTPUT_DIR}/decade_statistics\",\n",
    "                file_name_suffix=\".csv\",\n",
    "                num_shards=1\n",
    "            )\n",
    "    )\n",
    "\n",
    "    # Output 4 - Rating distribution buckets\n",
    "    rating_buckets = (\n",
    "        movies\n",
    "        | \"CreateRatingBuckets\" >> beam.Map(\n",
    "            lambda r: (int(r[\"averageRating\"]), 1)\n",
    "        )\n",
    "        | \"SumRatingBuckets\" >> beam.CombinePerKey(sum)\n",
    "    )\n",
    "\n",
    "    rating_bucket_header = p | \"RatingBucketHeader\" >> beam.Create(\n",
    "        [format_csv_line((\"rating_bucket\", \"movie_count\"))]\n",
    "    )\n",
    "\n",
    "    rating_bucket_rows = (\n",
    "        rating_buckets\n",
    "        | \"FormatRatingBuckets\" >> beam.Map(\n",
    "            lambda kv: format_csv_line((f\"{kv[0]}-{kv[0]+1}\", kv[1]))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    _ = ((rating_bucket_header, rating_bucket_rows)\n",
    "         | \"RatingBucketFlatten\" >> beam.Flatten()\n",
    "         | \"WriteRatingBucketCSV\" >> beam.io.WriteToText(\n",
    "                file_path_prefix=f\"{OUTPUT_DIR}/rating_distribution\",\n",
    "                file_name_suffix=\".csv\",\n",
    "                num_shards=1\n",
    "            )\n",
    "    )\n",
    "\n",
    "    # Output 5 - Popular vs Niche movies analysis\n",
    "    popularity_category = (\n",
    "        movies\n",
    "        | \"CategorizePopularity\" >> beam.Map(\n",
    "            lambda r: (\n",
    "                \"Popular\" if r[\"numRatings\"] >= 100 \n",
    "                else \"Moderate\" if r[\"numRatings\"] >= 50 \n",
    "                else \"Niche\",\n",
    "                (r[\"averageRating\"], 1)\n",
    "            )\n",
    "        )\n",
    "        | \"GroupByPopularity\" >> beam.GroupByKey()\n",
    "        | \"ComputePopularityStats\" >> beam.Map(\n",
    "            lambda kv: (\n",
    "                kv[0],\n",
    "                len(list(kv[1])),\n",
    "                sum(x[0] for x in kv[1]) / len(list(kv[1]))\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    popularity_header = p | \"PopularityHeader\" >> beam.Create(\n",
    "        [format_csv_line((\"popularity_category\", \"movie_count\", \"avg_rating\"))]\n",
    "    )\n",
    "\n",
    "    popularity_rows = (\n",
    "        popularity_category\n",
    "        | \"FormatPopularityRows\" >> beam.Map(\n",
    "            lambda t: format_csv_line((t[0], t[1], f\"{t[2]:.2f}\"))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    _ = ((popularity_header, popularity_rows)\n",
    "         | \"PopularityFlatten\" >> beam.Flatten()\n",
    "         | \"WritePopularityCSV\" >> beam.io.WriteToText(\n",
    "                file_path_prefix=f\"{OUTPUT_DIR}/popularity_analysis\",\n",
    "                file_name_suffix=\".csv\",\n",
    "                num_shards=1\n",
    "            )\n",
    "    )\n",
    "\n",
    "print(\"\\n Pipeline completed successfully !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
